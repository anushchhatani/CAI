{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6S56G-EeiwG",
        "outputId": "a5822613-bd41-4d9b-9c3e-869486b96905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Installing NLTK\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Importing the word_tokenize function and FreqDist class from nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1TjCjAsfFL9",
        "outputId": "ccebd82f-c7f4-4a4d-aacf-5f8a8bd6788d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Creating a variable ‘text’ which is containing a paragraph with the 4 sentences\n",
        "text = \"\"\"Natural language processing (NLP) is a fascinating area of artificial intelligence.\n",
        "It enables computers to understand and interpret human language. NLP is used in various applications like chatbots, translation, and sentiment analysis.\n",
        "By breaking down language into smaller components, NLP helps machines gain insights from text data.\n",
        "The potential applications of NLP are continuously expanding as technology advances.\"\"\""
      ],
      "metadata": {
        "id": "YcUGS-ydff_u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Using word_tokenize to tokenize the text into words\n",
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "6jVtCBoefpdl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Printing the list of tokens\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owrzLkLqg0-4",
        "outputId": "83bfea3d-aa53-4a4a-d91f-94576ce0a569"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'area', 'of', 'artificial', 'intelligence', '.', 'It', 'enables', 'computers', 'to', 'understand', 'and', 'interpret', 'human', 'language', '.', 'NLP', 'is', 'used', 'in', 'various', 'applications', 'like', 'chatbots', ',', 'translation', ',', 'and', 'sentiment', 'analysis', '.', 'By', 'breaking', 'down', 'language', 'into', 'smaller', 'components', ',', 'NLP', 'helps', 'machines', 'gain', 'insights', 'from', 'text', 'data', '.', 'The', 'potential', 'applications', 'of', 'NLP', 'are', 'continuously', 'expanding', 'as', 'technology', 'advances', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Counting the number of tokens in the text\n",
        "num_tokens = len(tokens)\n",
        "print(\"Number of tokens:\", num_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brPed5jehBUE",
        "outputId": "d6ef1ddb-f698-4e6b-86e3-7b243f86a3de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens: 68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Identifying the frequency of each token\n",
        "frequency_dist = FreqDist(tokens)\n",
        "print(\"Frequency of each token:\", frequency_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhtlkz5ChEOB",
        "outputId": "ad375285-9e4b-4f93-c4fc-561e55786459"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency of each token: <FreqDist with 53 samples and 68 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the frequency distribution\n",
        "print(\"Frequency distribution of tokens:\")\n",
        "for token, freq in frequency_dist.items():\n",
        "    print(f\"{token}: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwuRcexlhL9-",
        "outputId": "85b36bc9-5a23-4d03-cf32-b44b098566a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency distribution of tokens:\n",
            "Natural: 1\n",
            "language: 3\n",
            "processing: 1\n",
            "(: 1\n",
            "NLP: 4\n",
            "): 1\n",
            "is: 2\n",
            "a: 1\n",
            "fascinating: 1\n",
            "area: 1\n",
            "of: 2\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            ".: 5\n",
            "It: 1\n",
            "enables: 1\n",
            "computers: 1\n",
            "to: 1\n",
            "understand: 1\n",
            "and: 2\n",
            "interpret: 1\n",
            "human: 1\n",
            "used: 1\n",
            "in: 1\n",
            "various: 1\n",
            "applications: 2\n",
            "like: 1\n",
            "chatbots: 1\n",
            ",: 3\n",
            "translation: 1\n",
            "sentiment: 1\n",
            "analysis: 1\n",
            "By: 1\n",
            "breaking: 1\n",
            "down: 1\n",
            "into: 1\n",
            "smaller: 1\n",
            "components: 1\n",
            "helps: 1\n",
            "machines: 1\n",
            "gain: 1\n",
            "insights: 1\n",
            "from: 1\n",
            "text: 1\n",
            "data: 1\n",
            "The: 1\n",
            "potential: 1\n",
            "are: 1\n",
            "continuously: 1\n",
            "expanding: 1\n",
            "as: 1\n",
            "technology: 1\n",
            "advances: 1\n"
          ]
        }
      ]
    }
  ]
}